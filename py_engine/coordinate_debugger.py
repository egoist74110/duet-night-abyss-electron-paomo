"""
åæ ‡è°ƒè¯•å’Œä¿®å¤å·¥å…·
ä¸“é—¨ç”¨äºè§£å†³é¼ æ ‡ç‚¹å‡»ä½ç½®ä¸å‡†ç¡®çš„é—®é¢˜
"""
import pyautogui
import cv2
import numpy as np
import time
import platform
import json
from typing import Tuple, Dict, Any


class CoordinateDebugger:
    """åæ ‡è°ƒè¯•å™¨ - ä¸“é—¨è§£å†³ç‚¹å‡»ä½ç½®ä¸å‡†ç¡®é—®é¢˜"""
    
    def __init__(self, window_capture, human_mouse, image_recognition):
        """
        åˆå§‹åŒ–åæ ‡è°ƒè¯•å™¨
        
        Args:
            window_capture: çª—å£æ•è·å®ä¾‹
            human_mouse: é¼ æ ‡æ§åˆ¶å®ä¾‹
            image_recognition: å›¾åƒè¯†åˆ«å®ä¾‹
        """
        self.window_capture = window_capture
        self.human_mouse = human_mouse
        self.image_recognition = image_recognition
        self.platform = platform.system()
        
        # è·å–å±å¹•ä¿¡æ¯
        self.screen_width, self.screen_height = pyautogui.size()
        print(f"[INFO] åæ ‡è°ƒè¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"[INFO] å¹³å°: {self.platform}")
        print(f"[INFO] å±å¹•å°ºå¯¸: {self.screen_width}x{self.screen_height}")
        
    def comprehensive_coordinate_test(self, template_path: str, template_name: str) -> Dict[str, Any]:
        """
        å…¨é¢çš„åæ ‡æµ‹è¯• - è¿™æ˜¯è§£å†³ç‚¹å‡»ä½ç½®é—®é¢˜çš„æ ¸å¿ƒåŠŸèƒ½
        
        Args:
            template_path: æ¨¡æ¿å›¾ç‰‡è·¯å¾„
            template_name: æ¨¡æ¿åç§°
            
        Returns:
            Dict: è¯¦ç»†çš„æµ‹è¯•ç»“æœå’Œä¿®å¤å»ºè®®
        """
        print("=" * 60)
        print(f"ğŸ¯ å¼€å§‹å…¨é¢åæ ‡æµ‹è¯•: {template_name}")
        print("=" * 60)
        
        result = {
            'template_name': template_name,
            'template_path': template_path,
            'platform': self.platform,
            'screen_info': {
                'width': self.screen_width,
                'height': self.screen_height
            },
            'tests': {},
            'recommendations': [],
            'success': False
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ¨¡æ¿å¹¶è¯†åˆ«
            print("ğŸ“¸ ç¬¬ä¸€æ­¥ï¼šå›¾åƒè¯†åˆ«æµ‹è¯•")
            recognition_result = self._test_image_recognition(template_path, template_name)
            result['tests']['recognition'] = recognition_result
            
            if not recognition_result['found']:
                result['recommendations'].append({
                    'type': 'error',
                    'message': f'å›¾åƒè¯†åˆ«å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåæ ‡æµ‹è¯•ã€‚ç½®ä¿¡åº¦: {recognition_result["confidence"]:.3f}'
                })
                return result
            
            # ç¬¬äºŒæ­¥ï¼šåæ ‡è½¬æ¢æµ‹è¯•
            print("\nğŸ”„ ç¬¬äºŒæ­¥ï¼šåæ ‡è½¬æ¢æµ‹è¯•")
            conversion_result = self._test_coordinate_conversion(recognition_result)
            result['tests']['conversion'] = conversion_result
            
            # ç¬¬ä¸‰æ­¥ï¼šé¼ æ ‡ç§»åŠ¨æµ‹è¯•ï¼ˆä¸ç‚¹å‡»ï¼‰
            print("\nğŸ–±ï¸ ç¬¬ä¸‰æ­¥ï¼šé¼ æ ‡ç§»åŠ¨ç²¾åº¦æµ‹è¯•")
            movement_result = self._test_mouse_movement(conversion_result['screen_coords'])
            result['tests']['movement'] = movement_result
            
            # ç¬¬å››æ­¥ï¼šç‚¹å‡»ç²¾åº¦æµ‹è¯•
            print("\nğŸ¯ ç¬¬å››æ­¥ï¼šç‚¹å‡»ç²¾åº¦æµ‹è¯•")
            click_result = self._test_click_accuracy(conversion_result['screen_coords'])
            result['tests']['click'] = click_result
            
            # ç¬¬äº”æ­¥ï¼šç”Ÿæˆä¿®å¤å»ºè®®
            print("\nğŸ’¡ ç¬¬äº”æ­¥ï¼šç”Ÿæˆä¿®å¤å»ºè®®")
            self._generate_coordinate_recommendations(result)
            
            # åˆ¤æ–­æ•´ä½“æˆåŠŸç‡
            result['success'] = (
                recognition_result['found'] and
                movement_result['accuracy'] < 5 and  # ç§»åŠ¨è¯¯å·®å°äº5åƒç´ 
                click_result['success']
            )
            
            print(f"\nğŸ‰ åæ ‡æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸç‡: {'âœ… ä¼˜ç§€' if result['success'] else 'âš ï¸ éœ€è¦ä¼˜åŒ–'}")
            
        except Exception as e:
            print(f"âŒ åæ ‡æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
            result['error'] = str(e)
            result['recommendations'].append({
                'type': 'error',
                'message': f'æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {str(e)}'
            })
        
        return result
    
    def _test_image_recognition(self, template_path: str, template_name: str) -> Dict[str, Any]:
        """æµ‹è¯•å›¾åƒè¯†åˆ«"""
        try:
            # åŠ è½½æ¨¡æ¿
            success = self.image_recognition.load_template('coord_test', template_path)
            if not success:
                return {'found': False, 'error': 'æ— æ³•åŠ è½½æ¨¡æ¿å›¾ç‰‡'}
            
            # è·å–æˆªå›¾
            screenshot = self.window_capture.capture()
            if screenshot is None:
                return {'found': False, 'error': 'æ— æ³•è·å–æ¸¸æˆçª—å£æˆªå›¾'}
            
            print(f"   ğŸ“¸ æˆªå›¾å°ºå¯¸: {screenshot.shape[1]}x{screenshot.shape[0]}")
            
            # æ‰§è¡Œè¯†åˆ«
            found, position, confidence = self.image_recognition.match_template(
                screenshot, 'coord_test', 0.6  # ä½¿ç”¨è¾ƒä½é˜ˆå€¼ç¡®ä¿èƒ½æ‰¾åˆ°
            )
            
            result = {
                'found': found,
                'position': position,
                'confidence': confidence,
                'screenshot_size': (screenshot.shape[1], screenshot.shape[0])
            }
            
            if found:
                print(f"   âœ… è¯†åˆ«æˆåŠŸ: ä½ç½®({position[0]}, {position[1]}), ç½®ä¿¡åº¦: {confidence:.3f}")
            else:
                print(f"   âŒ è¯†åˆ«å¤±è´¥: æœ€é«˜ç½®ä¿¡åº¦: {confidence:.3f}")
            
            return result
            
        except Exception as e:
            print(f"   âŒ è¯†åˆ«æµ‹è¯•å‡ºé”™: {e}")
            return {'found': False, 'error': str(e)}
    
    def _test_coordinate_conversion(self, recognition_result: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•åæ ‡è½¬æ¢"""
        try:
            if not recognition_result['found']:
                return {'error': 'å›¾åƒè¯†åˆ«å¤±è´¥ï¼Œæ— æ³•æµ‹è¯•åæ ‡è½¬æ¢'}
            
            rel_x, rel_y = recognition_result['position']
            print(f"   ğŸ” è¯†åˆ«åˆ°çš„ç›¸å¯¹åæ ‡: ({rel_x}, {rel_y})")
            
            # ä½¿ç”¨çª—å£æ•è·çš„åæ ‡è½¬æ¢æ–¹æ³•
            screen_x, screen_y = self.window_capture.convert_relative_to_screen_coords(rel_x, rel_y)
            print(f"   ğŸ”„ è½¬æ¢åçš„å±å¹•åæ ‡: ({screen_x}, {screen_y})")
            
            # éªŒè¯åæ ‡æ˜¯å¦åœ¨å±å¹•èŒƒå›´å†…
            in_bounds = (0 <= screen_x <= self.screen_width and 0 <= screen_y <= self.screen_height)
            print(f"   ğŸ“ åæ ‡èŒƒå›´æ£€æŸ¥: {'âœ… åœ¨èŒƒå›´å†…' if in_bounds else 'âŒ è¶…å‡ºèŒƒå›´'}")
            
            # è®¡ç®—åæ ‡è½¬æ¢çš„åˆç†æ€§
            screenshot_size = recognition_result['screenshot_size']
            conversion_ratio_x = screen_x / screenshot_size[0] if screenshot_size[0] > 0 else 0
            conversion_ratio_y = screen_y / screenshot_size[1] if screenshot_size[1] > 0 else 0
            
            print(f"   ğŸ“Š è½¬æ¢æ¯”ä¾‹: X={conversion_ratio_x:.3f}, Y={conversion_ratio_y:.3f}")
            
            result = {
                'relative_coords': (rel_x, rel_y),
                'screen_coords': (screen_x, screen_y),
                'in_bounds': in_bounds,
                'conversion_ratio': (conversion_ratio_x, conversion_ratio_y),
                'screenshot_size': screenshot_size
            }
            
            return result
            
        except Exception as e:
            print(f"   âŒ åæ ‡è½¬æ¢æµ‹è¯•å‡ºé”™: {e}")
            return {'error': str(e)}
    
    def _test_mouse_movement(self, target_coords: Tuple[int, int]) -> Dict[str, Any]:
        """æµ‹è¯•é¼ æ ‡ç§»åŠ¨ç²¾åº¦"""
        try:
            target_x, target_y = target_coords
            print(f"   ğŸ¯ ç›®æ ‡ä½ç½®: ({target_x}, {target_y})")
            
            # è®°å½•ç§»åŠ¨å‰ä½ç½®
            before_x, before_y = pyautogui.position()
            print(f"   ğŸ“ ç§»åŠ¨å‰ä½ç½®: ({before_x}, {before_y})")
            
            # æ‰§è¡Œç§»åŠ¨
            print(f"   ğŸ–±ï¸ å¼€å§‹ç§»åŠ¨é¼ æ ‡...")
            pyautogui.moveTo(target_x, target_y, duration=0.5)
            time.sleep(0.2)  # ç­‰å¾…ç§»åŠ¨å®Œæˆ
            
            # è®°å½•ç§»åŠ¨åä½ç½®
            after_x, after_y = pyautogui.position()
            print(f"   ğŸ“ ç§»åŠ¨åä½ç½®: ({after_x}, {after_y})")
            
            # è®¡ç®—ç²¾åº¦
            error_x = abs(after_x - target_x)
            error_y = abs(after_y - target_y)
            total_error = (error_x ** 2 + error_y ** 2) ** 0.5
            
            print(f"   ğŸ“ ç§»åŠ¨è¯¯å·®: X={error_x}, Y={error_y}, æ€»è¯¯å·®={total_error:.1f}åƒç´ ")
            
            # è¯„ä¼°ç²¾åº¦ç­‰çº§
            if total_error <= 2:
                accuracy_level = "ä¼˜ç§€"
            elif total_error <= 5:
                accuracy_level = "è‰¯å¥½"
            elif total_error <= 10:
                accuracy_level = "ä¸€èˆ¬"
            else:
                accuracy_level = "è¾ƒå·®"
            
            print(f"   ğŸ¯ ç§»åŠ¨ç²¾åº¦: {accuracy_level}")
            
            result = {
                'target_coords': (target_x, target_y),
                'before_coords': (before_x, before_y),
                'after_coords': (after_x, after_y),
                'error': (error_x, error_y),
                'accuracy': total_error,
                'accuracy_level': accuracy_level
            }
            
            return result
            
        except Exception as e:
            print(f"   âŒ é¼ æ ‡ç§»åŠ¨æµ‹è¯•å‡ºé”™: {e}")
            return {'error': str(e)}
    
    def _test_click_accuracy(self, target_coords: Tuple[int, int]) -> Dict[str, Any]:
        """æµ‹è¯•ç‚¹å‡»ç²¾åº¦"""
        try:
            target_x, target_y = target_coords
            print(f"   ğŸ¯ å‡†å¤‡ç‚¹å‡»ä½ç½®: ({target_x}, {target_y})")
            
            # è®°å½•ç‚¹å‡»å‰ä½ç½®
            before_x, before_y = pyautogui.position()
            
            # æ‰§è¡Œç‚¹å‡»ï¼ˆä½¿ç”¨human_mouseçš„ç²¾ç¡®ç‚¹å‡»æ–¹æ³•ï¼‰
            print(f"   ğŸ–±ï¸ æ‰§è¡Œç²¾ç¡®ç‚¹å‡»...")
            click_success = self.human_mouse.click(target_x, target_y)
            
            # è®°å½•ç‚¹å‡»åä½ç½®
            after_x, after_y = pyautogui.position()
            
            # è®¡ç®—ç‚¹å‡»ç²¾åº¦
            error_x = abs(after_x - target_x)
            error_y = abs(after_y - target_y)
            total_error = (error_x ** 2 + error_y ** 2) ** 0.5
            
            print(f"   ğŸ“ ç‚¹å‡»è¯¯å·®: X={error_x}, Y={error_y}, æ€»è¯¯å·®={total_error:.1f}åƒç´ ")
            print(f"   ğŸ¯ ç‚¹å‡»ç»“æœ: {'âœ… æˆåŠŸ' if click_success else 'âŒ å¤±è´¥'}")
            
            result = {
                'target_coords': (target_x, target_y),
                'before_coords': (before_x, before_y),
                'after_coords': (after_x, after_y),
                'error': (error_x, error_y),
                'accuracy': total_error,
                'success': click_success
            }
            
            return result
            
        except Exception as e:
            print(f"   âŒ ç‚¹å‡»æµ‹è¯•å‡ºé”™: {e}")
            return {'error': str(e), 'success': False}
    
    def _generate_coordinate_recommendations(self, result: Dict[str, Any]):
        """ç”Ÿæˆåæ ‡ä¿®å¤å»ºè®®"""
        recommendations = result['recommendations']
        tests = result['tests']
        
        # åˆ†æè¯†åˆ«ç»“æœ
        if 'recognition' in tests and tests['recognition']['found']:
            recommendations.append({
                'type': 'success',
                'message': f'âœ… å›¾åƒè¯†åˆ«æ­£å¸¸ï¼Œç½®ä¿¡åº¦: {tests["recognition"]["confidence"]:.3f}'
            })
        
        # åˆ†æåæ ‡è½¬æ¢
        if 'conversion' in tests and 'screen_coords' in tests['conversion']:
            conversion = tests['conversion']
            if conversion['in_bounds']:
                recommendations.append({
                    'type': 'success',
                    'message': 'âœ… åæ ‡è½¬æ¢æ­£å¸¸ï¼Œç›®æ ‡ä½ç½®åœ¨å±å¹•èŒƒå›´å†…'
                })
            else:
                recommendations.append({
                    'type': 'error',
                    'message': 'âŒ åæ ‡è½¬æ¢å¼‚å¸¸ï¼Œç›®æ ‡ä½ç½®è¶…å‡ºå±å¹•èŒƒå›´'
                })
                recommendations.append({
                    'type': 'fix',
                    'message': 'ğŸ”§ å»ºè®®æ£€æŸ¥çª—å£æ•è·çš„åæ ‡è½¬æ¢é€»è¾‘'
                })
        
        # åˆ†æé¼ æ ‡ç§»åŠ¨ç²¾åº¦
        if 'movement' in tests and 'accuracy' in tests['movement']:
            movement = tests['movement']
            accuracy = movement['accuracy']
            
            if accuracy <= 2:
                recommendations.append({
                    'type': 'success',
                    'message': f'âœ… é¼ æ ‡ç§»åŠ¨ç²¾åº¦ä¼˜ç§€ï¼Œè¯¯å·®ä»…{accuracy:.1f}åƒç´ '
                })
            elif accuracy <= 5:
                recommendations.append({
                    'type': 'good',
                    'message': f'ğŸŸ¢ é¼ æ ‡ç§»åŠ¨ç²¾åº¦è‰¯å¥½ï¼Œè¯¯å·®{accuracy:.1f}åƒç´ '
                })
            elif accuracy <= 10:
                recommendations.append({
                    'type': 'warning',
                    'message': f'âš ï¸ é¼ æ ‡ç§»åŠ¨ç²¾åº¦ä¸€èˆ¬ï¼Œè¯¯å·®{accuracy:.1f}åƒç´ '
                })
                recommendations.append({
                    'type': 'fix',
                    'message': 'ğŸ”§ å»ºè®®æ£€æŸ¥ç³»ç»ŸDPIè®¾ç½®æˆ–æ˜¾ç¤ºç¼©æ”¾'
                })
            else:
                recommendations.append({
                    'type': 'error',
                    'message': f'âŒ é¼ æ ‡ç§»åŠ¨ç²¾åº¦è¾ƒå·®ï¼Œè¯¯å·®{accuracy:.1f}åƒç´ '
                })
                recommendations.append({
                    'type': 'fix',
                    'message': 'ğŸ”§ å»ºè®®é‡æ–°æ ¡å‡†åæ ‡è½¬æ¢ç®—æ³•'
                })
        
        # åˆ†æç‚¹å‡»ç»“æœ
        if 'click' in tests:
            click = tests['click']
            if click.get('success', False):
                recommendations.append({
                    'type': 'success',
                    'message': 'âœ… ç‚¹å‡»åŠŸèƒ½æ­£å¸¸'
                })
            else:
                recommendations.append({
                    'type': 'error',
                    'message': 'âŒ ç‚¹å‡»åŠŸèƒ½å¼‚å¸¸'
                })
                recommendations.append({
                    'type': 'fix',
                    'message': 'ğŸ”§ å»ºè®®æ£€æŸ¥é¼ æ ‡æ§åˆ¶æƒé™æˆ–pyautoguié…ç½®'
                })
        
        # å¹³å°ç‰¹å®šå»ºè®®
        if self.platform == 'Darwin':  # macOS
            recommendations.append({
                'type': 'tip',
                'message': 'ğŸ’¡ macOSç”¨æˆ·ï¼šç¡®ä¿åº”ç”¨æœ‰è¾…åŠ©åŠŸèƒ½å’Œå±å¹•å½•åˆ¶æƒé™'
            })
            recommendations.append({
                'type': 'tip',
                'message': 'ğŸ’¡ macOSç”¨æˆ·ï¼šå¦‚æœä½¿ç”¨Retinaæ˜¾ç¤ºå™¨ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´åæ ‡ç¼©æ”¾'
            })
        elif self.platform == 'Windows':
            recommendations.append({
                'type': 'tip',
                'message': 'ğŸ’¡ Windowsç”¨æˆ·ï¼šç¡®ä¿ä»¥ç®¡ç†å‘˜æƒé™è¿è¡Œåº”ç”¨'
            })
            recommendations.append({
                'type': 'tip',
                'message': 'ğŸ’¡ Windowsç”¨æˆ·ï¼šæ£€æŸ¥æ˜¾ç¤ºç¼©æ”¾è®¾ç½®ï¼Œå»ºè®®ä½¿ç”¨100%ç¼©æ”¾'
            })
    
    def quick_position_test(self, x: int, y: int) -> Dict[str, Any]:
        """
        å¿«é€Ÿä½ç½®æµ‹è¯• - æµ‹è¯•æŒ‡å®šåæ ‡çš„ç‚¹å‡»ç²¾åº¦
        
        Args:
            x: Xåæ ‡
            y: Yåæ ‡
            
        Returns:
            Dict: æµ‹è¯•ç»“æœ
        """
        print(f"ğŸš€ å¿«é€Ÿä½ç½®æµ‹è¯•: ({x}, {y})")
        
        try:
            # ç§»åŠ¨åˆ°æŒ‡å®šä½ç½®
            print(f"   ğŸ–±ï¸ ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®...")
            pyautogui.moveTo(x, y, duration=0.3)
            time.sleep(0.1)
            
            # æ£€æŸ¥å®é™…ä½ç½®
            actual_x, actual_y = pyautogui.position()
            error_x = abs(actual_x - x)
            error_y = abs(actual_y - y)
            total_error = (error_x ** 2 + error_y ** 2) ** 0.5
            
            print(f"   ğŸ“ ç›®æ ‡ä½ç½®: ({x}, {y})")
            print(f"   ğŸ“ å®é™…ä½ç½®: ({actual_x}, {actual_y})")
            print(f"   ğŸ“ ä½ç½®è¯¯å·®: X={error_x}, Y={error_y}, æ€»è¯¯å·®={total_error:.1f}åƒç´ ")
            
            # æ‰§è¡Œç‚¹å‡»
            print(f"   ğŸ–±ï¸ æ‰§è¡Œç‚¹å‡»...")
            click_success = self.human_mouse.click(x, y)
            
            result = {
                'target': (x, y),
                'actual': (actual_x, actual_y),
                'error': (error_x, error_y),
                'total_error': total_error,
                'click_success': click_success,
                'accuracy_level': 'excellent' if total_error <= 2 else 'good' if total_error <= 5 else 'poor'
            }
            
            print(f"   ğŸ¯ æµ‹è¯•ç»“æœ: {'âœ… ä¼˜ç§€' if result['accuracy_level'] == 'excellent' else 'ğŸŸ¢ è‰¯å¥½' if result['accuracy_level'] == 'good' else 'âŒ éœ€è¦ä¼˜åŒ–'}")
            
            return result
            
        except Exception as e:
            print(f"   âŒ å¿«é€Ÿæµ‹è¯•å‡ºé”™: {e}")
            return {'error': str(e)}
    
    def save_debug_results(self, results: Dict[str, Any], filename: str = None):
        """ä¿å­˜è°ƒè¯•ç»“æœåˆ°æ–‡ä»¶"""
        try:
            if filename is None:
                filename = f"coordinate_debug_{int(time.time())}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"ğŸ’¾ è°ƒè¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è°ƒè¯•ç»“æœå¤±è´¥: {e}")


def create_coordinate_debugger(window_capture, human_mouse, image_recognition):
    """åˆ›å»ºåæ ‡è°ƒè¯•å™¨å®ä¾‹"""
    return CoordinateDebugger(window_capture, human_mouse, image_recognition)