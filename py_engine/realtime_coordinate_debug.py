#!/usr/bin/env python3
"""
å®æ—¶åæ ‡è°ƒè¯•å·¥å…·
å¸®åŠ©è¯Šæ–­ macOS HiDPI ç¯å¢ƒä¸‹çš„åæ ‡è½¬æ¢é—®é¢˜
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pyautogui
import cv2
import numpy as np
import time
from window_capture import WindowCapture
from image_recognition import ImageRecognition
from human_mouse import HumanMouse

def analyze_coordinate_problem():
    """åˆ†æåæ ‡é—®é¢˜çš„æ ¹æœ¬åŸå› """
    print("ğŸ” å®æ—¶åæ ‡é—®é¢˜è¯Šæ–­å·¥å…·")
    print("=" * 60)
    
    # è·å–åŸºç¡€ä¿¡æ¯
    logical_width, logical_height = pyautogui.size()
    print(f"ğŸ“± é€»è¾‘å±å¹•å°ºå¯¸: {logical_width}x{logical_height}")
    
    # è·å–å®é™…æˆªå›¾
    screenshot = pyautogui.screenshot()
    actual_width = screenshot.width
    actual_height = screenshot.height
    print(f"ğŸ“¸ å®é™…æˆªå›¾å°ºå¯¸: {actual_width}x{actual_height}")
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    scale_x = actual_width / logical_width
    scale_y = actual_height / logical_height
    print(f"ğŸ“ ç¼©æ”¾æ¯”ä¾‹: X={scale_x:.4f}, Y={scale_y:.4f}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸º HiDPI ç¯å¢ƒ
    is_hidpi = scale_x > 1.5 or scale_y > 1.5
    print(f"ğŸ–¥ï¸ HiDPI ç¯å¢ƒ: {'æ˜¯' if is_hidpi else 'å¦'}")
    
    print("\n" + "="*60)
    print("ğŸ¯ å¼€å§‹å®æ—¶åæ ‡æµ‹è¯•")
    print("è¯·åœ¨æ¸¸æˆä¸­æ‰¾åˆ°ç«å‰¯æœ¬å›¾æ ‡ï¼Œç„¶åæŒ‰å›è½¦é”®å¼€å§‹æµ‹è¯•...")
    input()
    
    # åˆ›å»ºå›¾åƒè¯†åˆ«å®ä¾‹
    image_recognition = ImageRecognition()
    window_capture = WindowCapture()
    
    # åŠ è½½ç«å‰¯æœ¬æ¨¡æ¿
    template_path = "static/dungeon/ç«.png"
    if not os.path.exists(template_path):
        template_path = "../static/dungeon/ç«.png"
    
    if not os.path.exists(template_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶: {template_path}")
        return
    
    success = image_recognition.load_template('fire', template_path)
    if not success:
        print(f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥: {template_path}")
        return
    
    print(f"âœ… æ¨¡æ¿åŠ è½½æˆåŠŸ: {template_path}")
    
    # æ‰§è¡Œè¯†åˆ«æµ‹è¯•
    print("\nğŸ” æ‰§è¡Œå›¾åƒè¯†åˆ«...")
    screenshot_cv = pyautogui.screenshot()
    screenshot_array = np.array(screenshot_cv)
    screenshot_bgr = cv2.cvtColor(screenshot_array, cv2.COLOR_RGB2BGR)
    
    found, position, confidence = image_recognition.match_template(screenshot_bgr, 'fire', 0.6)
    
    if not found:
        print(f"âŒ æœªæ‰¾åˆ°ç«å‰¯æœ¬å›¾æ ‡ï¼Œç½®ä¿¡åº¦: {confidence:.3f}")
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("  1. ç¡®ä¿æ¸¸æˆçª—å£ä¸­æœ‰ç«å‰¯æœ¬å›¾æ ‡")
        print("  2. å°è¯•é™ä½åŒ¹é…é˜ˆå€¼")
        print("  3. æ£€æŸ¥æ¨¡æ¿å›¾ç‰‡æ˜¯å¦ä¸æ¸¸æˆä¸­çš„å›¾æ ‡ä¸€è‡´")
        return
    
    print(f"âœ… æ‰¾åˆ°ç«å‰¯æœ¬å›¾æ ‡ï¼")
    print(f"   ğŸ“ è¯†åˆ«ä½ç½®: ({position[0]}, {position[1]})")
    print(f"   ğŸ¯ ç½®ä¿¡åº¦: {confidence:.3f}")
    
    # åˆ†æåæ ‡è½¬æ¢
    print(f"\nğŸ“ åæ ‡è½¬æ¢åˆ†æ:")
    
    # æ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨è¯†åˆ«åæ ‡
    direct_x, direct_y = position[0], position[1]
    print(f"   æ–¹æ³•1 (ç›´æ¥ä½¿ç”¨): ({direct_x}, {direct_y})")
    
    # æ–¹æ³•2ï¼šæŒ‰ç¼©æ”¾æ¯”ä¾‹è½¬æ¢
    if is_hidpi:
        scaled_x = position[0] / scale_x
        scaled_y = position[1] / scale_y
        print(f"   æ–¹æ³•2 (ç¼©æ”¾è½¬æ¢): ({scaled_x:.1f}, {scaled_y:.1f})")
    else:
        scaled_x, scaled_y = direct_x, direct_y
        print(f"   æ–¹æ³•2 (æ— éœ€ç¼©æ”¾): ({scaled_x}, {scaled_y})")
    
    # æ–¹æ³•3ï¼šä½¿ç”¨çª—å£æ•è·çš„è½¬æ¢æ–¹æ³•
    converted_x, converted_y = window_capture.convert_relative_to_screen_coords(position[0], position[1])
    print(f"   æ–¹æ³•3 (çª—å£è½¬æ¢): ({converted_x}, {converted_y})")
    
    # æ£€æŸ¥å“ªäº›åæ ‡åœ¨å±å¹•èŒƒå›´å†…
    print(f"\nâœ… åæ ‡æœ‰æ•ˆæ€§æ£€æŸ¥:")
    
    coords_to_test = [
        ("ç›´æ¥ä½¿ç”¨", direct_x, direct_y),
        ("ç¼©æ”¾è½¬æ¢", scaled_x, scaled_y),
        ("çª—å£è½¬æ¢", converted_x, converted_y)
    ]
    
    valid_coords = []
    for name, x, y in coords_to_test:
        is_valid = 0 <= x <= logical_width and 0 <= y <= logical_height
        status = "âœ… æœ‰æ•ˆ" if is_valid else "âŒ è¶…å‡ºèŒƒå›´"
        print(f"   {name}: ({x:.0f}, {y:.0f}) - {status}")
        if is_valid:
            valid_coords.append((name, x, y))
    
    if not valid_coords:
        print("\nâŒ æ‰€æœ‰è½¬æ¢æ–¹æ³•éƒ½äº§ç”Ÿäº†æ— æ•ˆåæ ‡ï¼")
        print("ğŸ’¡ å¯èƒ½çš„åŸå› ï¼š")
        print("  1. æ¸¸æˆçª—å£ä¸åœ¨ä¸»å±å¹•ä¸Š")
        print("  2. æ¸¸æˆçª—å£è¢«ç¼©æ”¾æˆ–ç§»åŠ¨")
        print("  3. åæ ‡è½¬æ¢ç®—æ³•éœ€è¦è°ƒæ•´")
        return
    
    # æµ‹è¯•æœ‰æ•ˆåæ ‡çš„ç‚¹å‡»æ•ˆæœ
    print(f"\nğŸ–±ï¸ æµ‹è¯•é¼ æ ‡ç§»åŠ¨æ•ˆæœ:")
    mouse = HumanMouse()
    
    for name, x, y in valid_coords:
        print(f"\næµ‹è¯• {name} åæ ‡: ({x:.0f}, {y:.0f})")
        
        # è·å–å½“å‰é¼ æ ‡ä½ç½®
        before_x, before_y = pyautogui.position()
        print(f"   ç§»åŠ¨å‰ä½ç½®: ({before_x}, {before_y})")
        
        # ç§»åŠ¨é¼ æ ‡
        try:
            pyautogui.moveTo(x, y, duration=0.5)
            time.sleep(0.2)
            
            # è·å–ç§»åŠ¨åä½ç½®
            after_x, after_y = pyautogui.position()
            print(f"   ç§»åŠ¨åä½ç½®: ({after_x}, {after_y})")
            
            # è®¡ç®—è¯¯å·®
            error_x = abs(after_x - x)
            error_y = abs(after_y - y)
            total_error = (error_x ** 2 + error_y ** 2) ** 0.5
            
            print(f"   ç§»åŠ¨è¯¯å·®: X={error_x:.0f}, Y={error_y:.0f}, æ€»è¯¯å·®={total_error:.1f}åƒç´ ")
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½ç½®æ­£ç¡®
            response = input(f"   é¼ æ ‡æ˜¯å¦ç§»åŠ¨åˆ°äº†ç«å‰¯æœ¬å›¾æ ‡ä¸Šï¼Ÿ(y/n): ")
            if response.lower() == 'y':
                print(f"ğŸ‰ æ‰¾åˆ°æ­£ç¡®çš„åæ ‡è½¬æ¢æ–¹æ³•: {name}")
                print(f"   æ­£ç¡®åæ ‡: ({x:.0f}, {y:.0f})")
                
                # ä¿å­˜ç»“æœ
                result = {
                    'method': name,
                    'original_position': position,
                    'converted_position': [int(x), int(y)],
                    'scale_factor': [scale_x, scale_y],
                    'is_hidpi': is_hidpi,
                    'confidence': confidence
                }
                
                import json
                with open('coordinate_fix_result.json', 'w') as f:
                    json.dump(result, f, indent=2)
                
                print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° coordinate_fix_result.json")
                return result
            
        except Exception as e:
            print(f"   âŒ ç§»åŠ¨å¤±è´¥: {e}")
    
    print("\nâŒ æ‰€æœ‰æ–¹æ³•éƒ½æ— æ³•æ­£ç¡®å®šä½åˆ°ç«å‰¯æœ¬å›¾æ ‡")
    print("ğŸ’¡ å»ºè®®è¿›ä¸€æ­¥è°ƒè¯•ï¼š")
    print("  1. æ£€æŸ¥æ¸¸æˆçª—å£æ˜¯å¦å®Œå…¨å¯è§")
    print("  2. å°è¯•è°ƒæ•´æ¸¸æˆçª—å£å¤§å°å’Œä½ç½®")
    print("  3. ç¡®è®¤æ¨¡æ¿å›¾ç‰‡ä¸æ¸¸æˆä¸­çš„å›¾æ ‡å®Œå…¨ä¸€è‡´")

if __name__ == "__main__":
    try:
        analyze_coordinate_problem()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()