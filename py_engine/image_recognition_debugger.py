"""
å›¾åƒè¯†åˆ«è°ƒè¯•å·¥å…·
ä¸“é—¨ç”¨äºåˆ†æå’Œä¼˜åŒ–å›¾åƒè¯†åˆ«æˆåŠŸç‡
"""
import cv2
import numpy as np
import os
import json
from typing import Dict, List, Tuple, Optional


class ImageRecognitionDebugger:
    """å›¾åƒè¯†åˆ«è°ƒè¯•å™¨ - å¸®åŠ©åˆ†æè¯†åˆ«é—®é¢˜å’Œä¼˜åŒ–å‚æ•°"""
    
    def __init__(self, image_recognition, window_capture):
        """
        åˆå§‹åŒ–è°ƒè¯•å™¨
        
        Args:
            image_recognition: å›¾åƒè¯†åˆ«å®ä¾‹
            window_capture: çª—å£æ•è·å®ä¾‹
        """
        self.image_recognition = image_recognition
        self.window_capture = window_capture
        self.debug_results = []
        
    def comprehensive_test(self, template_paths: Dict[str, str], 
                          thresholds: List[float] = None) -> Dict:
        """
        å…¨é¢æµ‹è¯•ä¸åŒé˜ˆå€¼ä¸‹çš„è¯†åˆ«æ•ˆæœ
        
        Args:
            template_paths: æ¨¡æ¿è·¯å¾„å­—å…¸ {'name': 'path'}
            thresholds: è¦æµ‹è¯•çš„é˜ˆå€¼åˆ—è¡¨
            
        Returns:
            Dict: è¯¦ç»†çš„æµ‹è¯•ç»“æœ
        """
        if thresholds is None:
            thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
        
        print("=" * 60)
        print("ğŸ” å¼€å§‹å…¨é¢å›¾åƒè¯†åˆ«æµ‹è¯•")
        print("=" * 60)
        
        # è·å–å½“å‰æˆªå›¾
        screenshot = self.window_capture.capture()
        if screenshot is None:
            return {'error': 'æ— æ³•è·å–æ¸¸æˆçª—å£æˆªå›¾'}
        
        print(f"ğŸ“¸ æˆªå›¾å°ºå¯¸: {screenshot.shape[1]}x{screenshot.shape[0]}")
        
        results = {
            'screenshot_info': {
                'width': screenshot.shape[1],
                'height': screenshot.shape[0],
                'channels': screenshot.shape[2] if len(screenshot.shape) > 2 else 1
            },
            'template_tests': {},
            'recommendations': []
        }
        
        # æµ‹è¯•æ¯ä¸ªæ¨¡æ¿
        for template_name, template_path in template_paths.items():
            print(f"\nğŸ¯ æµ‹è¯•æ¨¡æ¿: {template_name}")
            print(f"ğŸ“ è·¯å¾„: {template_path}")
            
            # åŠ è½½æ¨¡æ¿
            if not self.image_recognition.load_template(f"debug_{template_name}", template_path):
                print(f"âŒ æ— æ³•åŠ è½½æ¨¡æ¿: {template_path}")
                continue
            
            template_results = {
                'template_path': template_path,
                'threshold_tests': {},
                'best_result': None,
                'template_info': self._analyze_template(template_path)
            }
            
            best_confidence = 0.0
            best_threshold = 0.0
            
            # æµ‹è¯•ä¸åŒé˜ˆå€¼
            for threshold in thresholds:
                print(f"  ğŸ” æµ‹è¯•é˜ˆå€¼: {threshold:.2f}")
                
                found, position, confidence = self.image_recognition.match_template(
                    screenshot, f"debug_{template_name}", threshold
                )
                
                test_result = {
                    'found': found,
                    'position': position,
                    'confidence': confidence,
                    'threshold': threshold
                }
                
                template_results['threshold_tests'][threshold] = test_result
                
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_threshold = threshold
                    template_results['best_result'] = test_result
                
                status = "âœ… æ‰¾åˆ°" if found else "âŒ æœªæ‰¾åˆ°"
                print(f"    {status} - ç½®ä¿¡åº¦: {confidence:.3f}")
            
            results['template_tests'][template_name] = template_results
            
            # ç”Ÿæˆå»ºè®®
            self._generate_recommendations(template_name, template_results, results['recommendations'])
        
        # ä¿å­˜è°ƒè¯•ç»“æœ
        self._save_debug_results(results)
        
        # æ‰“å°æ€»ç»“
        self._print_summary(results)
        
        return results
    
    def _analyze_template(self, template_path: str) -> Dict:
        """åˆ†ææ¨¡æ¿å›¾åƒçš„ç‰¹å¾"""
        try:
            template = cv2.imread(template_path)
            if template is None:
                return {'error': 'æ— æ³•è¯»å–æ¨¡æ¿å›¾åƒ'}
            
            # åŸºæœ¬ä¿¡æ¯
            height, width = template.shape[:2]
            channels = template.shape[2] if len(template.shape) > 2 else 1
            
            # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œåˆ†æ
            if channels > 1:
                gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
            else:
                gray = template
            
            # è®¡ç®—å›¾åƒç‰¹å¾
            mean_brightness = np.mean(gray)
            std_brightness = np.std(gray)
            
            # è¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (width * height)
            
            # ç›´æ–¹å›¾åˆ†æ
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist_peak = np.argmax(hist)
            
            return {
                'width': width,
                'height': height,
                'channels': channels,
                'mean_brightness': float(mean_brightness),
                'std_brightness': float(std_brightness),
                'edge_density': float(edge_density),
                'histogram_peak': int(hist_peak),
                'size_category': self._categorize_size(width, height)
            }
            
        except Exception as e:
            return {'error': f'æ¨¡æ¿åˆ†æå¤±è´¥: {str(e)}'}
    
    def _categorize_size(self, width: int, height: int) -> str:
        """æ ¹æ®å°ºå¯¸åˆ†ç±»æ¨¡æ¿"""
        area = width * height
        if area < 1000:
            return 'small'  # å°å›¾æ ‡
        elif area < 5000:
            return 'medium'  # ä¸­ç­‰æŒ‰é’®
        else:
            return 'large'   # å¤§å‹å…ƒç´ 
    
    def _generate_recommendations(self, template_name: str, 
                                template_results: Dict, 
                                recommendations: List):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        best_result = template_results.get('best_result')
        template_info = template_results.get('template_info', {})
        
        if not best_result:
            recommendations.append({
                'template': template_name,
                'type': 'error',
                'message': f'{template_name}: æ‰€æœ‰é˜ˆå€¼ä¸‹éƒ½æ— æ³•è¯†åˆ«ï¼Œå»ºè®®æ£€æŸ¥æ¨¡æ¿å›¾åƒè´¨é‡'
            })
            return
        
        best_confidence = best_result['confidence']
        best_threshold = best_result['threshold']
        
        # åŸºäºç½®ä¿¡åº¦ç”Ÿæˆå»ºè®®
        if best_confidence >= 0.8:
            recommendations.append({
                'template': template_name,
                'type': 'excellent',
                'message': f'{template_name}: è¯†åˆ«æ•ˆæœä¼˜ç§€ (ç½®ä¿¡åº¦: {best_confidence:.3f})ï¼Œå»ºè®®é˜ˆå€¼: {best_threshold:.2f}'
            })
        elif best_confidence >= 0.65:
            recommendations.append({
                'template': template_name,
                'type': 'good',
                'message': f'{template_name}: è¯†åˆ«æ•ˆæœè‰¯å¥½ (ç½®ä¿¡åº¦: {best_confidence:.3f})ï¼Œå»ºè®®é˜ˆå€¼: {best_threshold:.2f}'
            })
        elif best_confidence >= 0.5:
            recommendations.append({
                'template': template_name,
                'type': 'warning',
                'message': f'{template_name}: è¯†åˆ«æ•ˆæœä¸€èˆ¬ (ç½®ä¿¡åº¦: {best_confidence:.3f})ï¼Œå»ºè®®é˜ˆå€¼: {best_threshold:.2f}ï¼Œè€ƒè™‘ä¼˜åŒ–æ¨¡æ¿å›¾åƒ'
            })
        else:
            recommendations.append({
                'template': template_name,
                'type': 'error',
                'message': f'{template_name}: è¯†åˆ«æ•ˆæœå·® (ç½®ä¿¡åº¦: {best_confidence:.3f})ï¼Œéœ€è¦é‡æ–°åˆ¶ä½œæ¨¡æ¿å›¾åƒ'
            })
        
        # åŸºäºæ¨¡æ¿ç‰¹å¾ç”Ÿæˆå»ºè®®
        if 'edge_density' in template_info:
            edge_density = template_info['edge_density']
            if edge_density < 0.1:
                recommendations.append({
                    'template': template_name,
                    'type': 'tip',
                    'message': f'{template_name}: è¾¹ç¼˜ç‰¹å¾è¾ƒå°‘ï¼Œå»ºè®®é€‰æ‹©è¾¹ç¼˜æ›´æ¸…æ™°çš„åŒºåŸŸä½œä¸ºæ¨¡æ¿'
                })
        
        if 'std_brightness' in template_info:
            std_brightness = template_info['std_brightness']
            if std_brightness < 20:
                recommendations.append({
                    'template': template_name,
                    'type': 'tip',
                    'message': f'{template_name}: å¯¹æ¯”åº¦è¾ƒä½ï¼Œå»ºè®®é€‰æ‹©å¯¹æ¯”åº¦æ›´é«˜çš„å›¾åƒåŒºåŸŸ'
                })
    
    def _save_debug_results(self, results: Dict):
        """ä¿å­˜è°ƒè¯•ç»“æœåˆ°æ–‡ä»¶"""
        try:
            debug_dir = 'debug_results'
            if not os.path.exists(debug_dir):
                os.makedirs(debug_dir)
            
            # ä¿å­˜JSONç»“æœ
            json_path = os.path.join(debug_dir, 'recognition_debug_results.json')
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nğŸ’¾ è°ƒè¯•ç»“æœå·²ä¿å­˜åˆ°: {json_path}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è°ƒè¯•ç»“æœå¤±è´¥: {e}")
    
    def _print_summary(self, results: Dict):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        
        template_tests = results.get('template_tests', {})
        recommendations = results.get('recommendations', [])
        
        # ç»Ÿè®¡å„ç±»ç»“æœ
        excellent_count = sum(1 for r in recommendations if r['type'] == 'excellent')
        good_count = sum(1 for r in recommendations if r['type'] == 'good')
        warning_count = sum(1 for r in recommendations if r['type'] == 'warning')
        error_count = sum(1 for r in recommendations if r['type'] == 'error')
        
        print(f"ğŸ“ˆ æµ‹è¯•æ¨¡æ¿æ•°é‡: {len(template_tests)}")
        print(f"âœ… ä¼˜ç§€è¯†åˆ«: {excellent_count}")
        print(f"ğŸŸ¢ è‰¯å¥½è¯†åˆ«: {good_count}")
        print(f"âš ï¸ éœ€è¦ä¼˜åŒ–: {warning_count}")
        print(f"âŒ è¯†åˆ«å¤±è´¥: {error_count}")
        
        print("\nğŸ¯ æ¨èè®¾ç½®:")
        
        # è®¡ç®—æ¨èçš„å…¨å±€é˜ˆå€¼
        all_confidences = []
        for template_name, template_result in template_tests.items():
            best_result = template_result.get('best_result')
            if best_result and best_result['confidence'] > 0.5:
                all_confidences.append(best_result['confidence'])
        
        if all_confidences:
            avg_confidence = np.mean(all_confidences)
            recommended_threshold = max(0.5, avg_confidence - 0.1)
            print(f"   æ¨èå…¨å±€é˜ˆå€¼: {recommended_threshold:.2f}")
            print(f"   å¹³å‡æœ€ä½³ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
        print("\nğŸ“‹ è¯¦ç»†å»ºè®®:")
        for rec in recommendations:
            icon = {
                'excellent': 'ğŸŒŸ',
                'good': 'âœ…',
                'warning': 'âš ï¸',
                'error': 'âŒ',
                'tip': 'ğŸ’¡'
            }.get(rec['type'], 'ğŸ“Œ')
            print(f"   {icon} {rec['message']}")
    
    def quick_test(self, template_name: str, template_path: str, 
                   threshold: float = 0.65) -> Dict:
        """
        å¿«é€Ÿæµ‹è¯•å•ä¸ªæ¨¡æ¿
        
        Args:
            template_name: æ¨¡æ¿åç§°
            template_path: æ¨¡æ¿è·¯å¾„
            threshold: æµ‹è¯•é˜ˆå€¼
            
        Returns:
            Dict: æµ‹è¯•ç»“æœ
        """
        print(f"ğŸš€ å¿«é€Ÿæµ‹è¯•: {template_name}")
        
        # è·å–æˆªå›¾
        screenshot = self.window_capture.capture()
        if screenshot is None:
            return {'error': 'æ— æ³•è·å–æ¸¸æˆçª—å£æˆªå›¾'}
        
        # åŠ è½½æ¨¡æ¿
        if not self.image_recognition.load_template(f"quick_{template_name}", template_path):
            return {'error': f'æ— æ³•åŠ è½½æ¨¡æ¿: {template_path}'}
        
        # æ‰§è¡Œè¯†åˆ«
        found, position, confidence = self.image_recognition.match_template(
            screenshot, f"quick_{template_name}", threshold
        )
        
        result = {
            'template_name': template_name,
            'template_path': template_path,
            'threshold': threshold,
            'found': found,
            'position': position,
            'confidence': confidence,
            'screenshot_size': (screenshot.shape[1], screenshot.shape[0])
        }
        
        # æ‰“å°ç»“æœ
        status = "âœ… æ‰¾åˆ°" if found else "âŒ æœªæ‰¾åˆ°"
        print(f"   {status} - ç½®ä¿¡åº¦: {confidence:.3f}")
        
        if found:
            print(f"   ğŸ“ ä½ç½®: ({position[0]}, {position[1]})")
        
        # ç”Ÿæˆå»ºè®®
        if confidence >= 0.8:
            print(f"   ğŸŒŸ è¯†åˆ«æ•ˆæœä¼˜ç§€ï¼Œå½“å‰é˜ˆå€¼ {threshold:.2f} åˆé€‚")
        elif confidence >= 0.65:
            print(f"   âœ… è¯†åˆ«æ•ˆæœè‰¯å¥½ï¼Œå½“å‰é˜ˆå€¼ {threshold:.2f} åˆé€‚")
        elif confidence >= 0.5:
            print(f"   âš ï¸ è¯†åˆ«æ•ˆæœä¸€èˆ¬ï¼Œå»ºè®®é™ä½é˜ˆå€¼åˆ° {max(0.5, confidence - 0.05):.2f}")
        else:
            print(f"   âŒ è¯†åˆ«æ•ˆæœå·®ï¼Œå»ºè®®æ£€æŸ¥æ¨¡æ¿å›¾åƒè´¨é‡æˆ–é™ä½é˜ˆå€¼åˆ° 0.5")
        
        return result


def create_debugger(image_recognition, window_capture):
    """åˆ›å»ºå›¾åƒè¯†åˆ«è°ƒè¯•å™¨å®ä¾‹"""
    return ImageRecognitionDebugger(image_recognition, window_capture)